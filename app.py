####
import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import os

# 1. Î™®Îç∏ Ï†ïÏùò (NotebookÏóêÏÑú Í∞ÄÏ†∏Ïò¥)
class ASLLinearNet(nn.Module):
    """nn.Linear Í∏∞Î∞ò ASL Î∂ÑÎ•ò Î™®Îç∏ (28x28 Grayscale)"""
    
    def __init__(self, input_size=784, num_classes=24):
        super(ASLLinearNet, self).__init__()
        
        self.fc1 = nn.Linear(input_size, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.dropout1 = nn.Dropout(0.3)
        
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout2 = nn.Dropout(0.3)
        
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.dropout3 = nn.Dropout(0.2)
        
        self.fc4 = nn.Linear(128, num_classes)
        
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout1(x)
        
        x = self.fc2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.dropout2(x)
        
        x = self.fc3(x)
        x = self.bn3(x)
        x = self.relu(x)
        x = self.dropout3(x)
        
        x = self.fc4(x)
        
        return x

# 2. ÏÑ§Ï†ï Î∞è ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ
MODEL_PATH = './model/best_nnLinear_model.pth'
# A-I (0-8), K-Y (9-23) - JÏôÄ Z Ï†úÏô∏
CLASS_NAMES = [chr(65 + i) if i < 9 else chr(65 + i + 1) for i in range(24)]

# 3. Î™®Îç∏ Î°úÎìú Ìï®Ïàò
@st.cache_resource
def load_model():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = ASLLinearNet(num_classes=24)
    
    if os.path.exists(MODEL_PATH):
        try:
            state_dict = torch.load(MODEL_PATH, map_location=device)
            model.load_state_dict(state_dict)
            model.to(device)
            model.eval()
            return model, device
        except Exception as e:
            st.error(f"Î™®Îç∏ Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
            return None, device
    else:
        st.error(f"Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {MODEL_PATH}")
        return None, device

# 4. Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò
def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((28, 28)),
        transforms.Grayscale(num_output_channels=1),  # Grayscale Î≥ÄÌôò
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))  # 1Ï±ÑÎÑê Ï†ïÍ∑úÌôî
    ])
    return transform(image).unsqueeze(0)  # Î∞∞Ïπò Ï∞®Ïõê Ï∂îÍ∞Ä

# 5. Î©îÏù∏ UI
def main():
    st.set_page_config(page_title="ASL ÏàòÏñ¥ Î∂ÑÎ•òÍ∏∞", page_icon="‚úã")
    
    st.title("ü§ü AI ASL Classifier")
    st.write("Ïù¥ÎØ∏ÏßÄÎ•º ÏóÖÎ°úÎìúÌïòÍ±∞ÎÇò ÏÉòÌîå Ïù¥ÎØ∏ÏßÄÎ•º ÏÑ†ÌÉùÌïòÎ©¥ Ïñ¥Îñ§ ÏïåÌååÎ≤≥ ÏàòÏñ¥Ïù∏ÏßÄ ÏïåÎ†§Ï§çÎãàÎã§!")
    
    # ÏÇ¨Ïù¥ÎìúÎ∞î
    st.sidebar.header("üìå Ï†ïÎ≥¥")
    st.sidebar.info("Ïù¥ Ïï±ÏùÄ PyTorchÎ°ú ÌïôÏäµÎêú Îã§Ï∏µ Ïã†Í≤ΩÎßù Î™®Îç∏(nn.Linear)ÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.")
    st.sidebar.write("**Î™®Îç∏ Íµ¨Ï°∞:**")
    st.sidebar.write("- ÏûÖÎ†•: 28√ó28 Grayscale")
    st.sidebar.write("- Î†àÏù¥Ïñ¥: 784‚Üí512‚Üí256‚Üí128‚Üí24")
    st.sidebar.write("- BatchNorm + Dropout Ï†ÅÏö©")
    
    # Î™®Îç∏ Î°úÎìú
    model, device = load_model()
    
    if model is None:
        return

    # Ïù¥ÎØ∏ÏßÄ ÏóÖÎ°úÎìú
    st.subheader("üì§ ÏóÖÎ°úÎìú")
    
    uploaded_file = st.file_uploader("ÏàòÏñ¥ Ïù¥ÎØ∏ÏßÄÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî (JPG, PNG)", type=["jpg", "jpeg", "png"])
    
    image = None
    image_source = ""
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert('RGB')
        image_source = uploaded_file.name
    
    # Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏÑ†ÌÉùÎêòÏóàÏùÑ Îïå Î∂ÑÏÑù ÏàòÌñâ
    if image is not None:
        try:
            # 1. ÏÑ†ÌÉùÎêú Ïù¥ÎØ∏ÏßÄ ÌëúÏãú
            st.subheader("üì∑ ÏÑ†ÌÉùÎêú Ïù¥ÎØ∏ÏßÄ")
            st.image(image, caption=f'{image_source}', use_container_width=True)
            
            st.write("---")  # Íµ¨Î∂ÑÏÑ†
            
            # 2. Î∂ÑÏÑù Î∞è Í≤∞Í≥º ÌëúÏãú
            st.subheader("üìä Î∂ÑÏÑù Í≤∞Í≥º")
            
            with st.spinner('Î∂ÑÏÑù Ï§ë...'):
                # Ï†ÑÏ≤òÎ¶¨ Î∞è ÏòàÏ∏°
                input_tensor = preprocess_image(image).to(device)
                
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probabilities = torch.nn.functional.softmax(outputs, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    
                    predicted_idx = predicted.item()
                    predicted_class = CLASS_NAMES[predicted_idx]
                    confidence_score = confidence.item() * 100
                
                # Í≤∞Í≥º ÌëúÏãú
                st.success(f"### ÏòàÏ∏°: **{predicted_class}**")
                st.metric(label="Ïã†Î¢∞ÎèÑ", value=f"{confidence_score:.2f}%")
                
                # Top 3 ÌôïÎ•† ÌëúÏãú
                st.write("---")
                st.write("**ÏÉÅÏúÑ 3Í∞ú ÏòàÏ∏°:**")
                top3_prob, top3_idx = torch.topk(probabilities, 3)
                for i in range(3):
                    cls = CLASS_NAMES[top3_idx[0][i].item()]
                    prob = top3_prob[0][i].item() * 100
                    st.write(f"{i+1}. **{cls}**: {prob:.2f}%")
                    st.progress(int(prob))
                                
        except Exception as e:
            st.error(f"Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")


if __name__ == "__main__":
    main()
